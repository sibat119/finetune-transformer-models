{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_bert_for_ner_task.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7QMWKbfnPtJJTs2p+0rC0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "329ef6e56f8c4e0aa337c5396cab2392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_961c9b0d24f9498ebddc5502abe068f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8ac9e2e7574414ab62766c8ffbb1fdb",
              "IPY_MODEL_21cf81d6cd9f436a94ca1d441261792a"
            ]
          }
        },
        "961c9b0d24f9498ebddc5502abe068f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8ac9e2e7574414ab62766c8ffbb1fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f14f4dfb281418dbf99ae0bd7bba25e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34dba461826a4855a8a6f1a0ce5fb0e9"
          }
        },
        "21cf81d6cd9f436a94ca1d441261792a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a4fb3b13c804fc980e92282435b4836",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 699kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_990573dfd32040d6a078a0446c7d136a"
          }
        },
        "1f14f4dfb281418dbf99ae0bd7bba25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34dba461826a4855a8a6f1a0ce5fb0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a4fb3b13c804fc980e92282435b4836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "990573dfd32040d6a078a0446c7d136a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ecc357c2ef4a2593f9c85f057a366d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a6a9f47689042208a5f1d6f2e96210d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddd9efd193d547178e8d1760a05700a3",
              "IPY_MODEL_8325d41a705242f0b56dfc098e139529"
            ]
          }
        },
        "3a6a9f47689042208a5f1d6f2e96210d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddd9efd193d547178e8d1760a05700a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a270cee97dbf4abe9a9072e38324aec1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc532ce09cd942dd9aa35f0df51288ec"
          }
        },
        "8325d41a705242f0b56dfc098e139529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6baf67675ad848cf9e8571eeb44cc60b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 283B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2992b632ec0424ab3951e8f50d6d865"
          }
        },
        "a270cee97dbf4abe9a9072e38324aec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc532ce09cd942dd9aa35f0df51288ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6baf67675ad848cf9e8571eeb44cc60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2992b632ec0424ab3951e8f50d6d865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f67ae1bd2cb4ac18c28ea970e99b843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9f1415aedef437b86f0d989f81f917b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6089ee741f9b4e97af0f61a67832ec38",
              "IPY_MODEL_4693d060ddbf4e6db60c44374cb8236f"
            ]
          }
        },
        "c9f1415aedef437b86f0d989f81f917b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6089ee741f9b4e97af0f61a67832ec38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41bdcedaca7f4e738c6547d920c91506",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c7d04d2f865474f933612a1d66eb758"
          }
        },
        "4693d060ddbf4e6db60c44374cb8236f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_519101dd5eb34071abc46be234ba1cf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.99MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7c6612af21e41b18ce282b59ee57a13"
          }
        },
        "41bdcedaca7f4e738c6547d920c91506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c7d04d2f865474f933612a1d66eb758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "519101dd5eb34071abc46be234ba1cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7c6612af21e41b18ce282b59ee57a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d835b37cb0294de4bffa7c94200aac48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_325ff2bcd4924920bc709a0c72e6472e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61c9cd2045d74133bcac7fab657b878c",
              "IPY_MODEL_e54b8805bcc046dc940f0e582365b04b"
            ]
          }
        },
        "325ff2bcd4924920bc709a0c72e6472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61c9cd2045d74133bcac7fab657b878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39f58ed60b6b438299e734c90e8a384b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0611a887fffc4d898ea3fc74a5fb027c"
          }
        },
        "e54b8805bcc046dc940f0e582365b04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_355184d1dfcf47f29cbd67f7c55bfe2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [05:10&lt;00:00, 1.84B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d7d0605d7564a4bbedb0d153b6cc961"
          }
        },
        "39f58ed60b6b438299e734c90e8a384b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0611a887fffc4d898ea3fc74a5fb027c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "355184d1dfcf47f29cbd67f7c55bfe2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d7d0605d7564a4bbedb0d153b6cc961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ceb2de58fcd42f1a2eb943f711c6bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f48cbbf5e64c4a3f97f56db2e8a7ca8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0eabd9975b84593b6101a8724c84564",
              "IPY_MODEL_221e29d7175442c59dfedcca6db58099"
            ]
          }
        },
        "f48cbbf5e64c4a3f97f56db2e8a7ca8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0eabd9975b84593b6101a8724c84564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75df1dbb46174741bd4ebe4d069f056e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a17b091989964d52ad8c5c7b612b7c10"
          }
        },
        "221e29d7175442c59dfedcca6db58099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_109ab3f3225a457da38326a0baba85a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [05:10&lt;00:00, 1.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f96037074c994e36a99d15c768ced08e"
          }
        },
        "75df1dbb46174741bd4ebe4d069f056e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a17b091989964d52ad8c5c7b612b7c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109ab3f3225a457da38326a0baba85a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f96037074c994e36a99d15c768ced08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sibat119/finetune-transformer-models/blob/main/finetune_bert_for_ner_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYtEY7Zum5YM"
      },
      "source": [
        "#BERT Fine-Tuning with PyTorch for Named Entity Recognition task\n",
        "\n",
        "Use BERT with the huggingface PyTorch library to quickly and efficiently fine-tune a model to get near state of the art performance in Named Entity Recognition. More broadly, I describe the practical application of transfer learning in NLP to create high performance models with minimal effort on a range of NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgQYxxdnUoP"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTXMlSo6nYUo"
      },
      "source": [
        "# 1.1. Using Colab GPU for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h47mbDxQnd5C"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV5IvH0tm1_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46b04bc-1815-444c-a581-461e4e44be61"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otnb6jwrnzHO"
      },
      "source": [
        "# 1.2. Installing the Hugging Face Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7At-o-wOnqwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46af7d86-f2a9-43e3-edb1-37f1321bb182"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZ9FHfYn_Sz"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_ner.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_ner.py) example script from huggingface. This `run_ner.py` also uses [utils_ner.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/utils_ner.py) file which we also followed for this finetuning process.\n",
        "\n",
        "`run_ner.py` is a helpful utility which allows you to pick which NER task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
        "\n",
        "\n",
        "\n",
        "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ7pKv_yoiC5"
      },
      "source": [
        "# 2. Loading Conll-2003 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmzeaudop1X"
      },
      "source": [
        "# 2.1. Download & Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZshXY16ow-H"
      },
      "source": [
        "We'll use the wget package to download the dataset to the Colab instance's file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8cPbPapn4Gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced67191-7011-4111-fe15-d2c63618bfb4"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=843c923c5bd8e9e58c5410a70170eb8628dee2c12f0246c459a284ae3f456c90\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAsOh58co1B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61e84e2-f472-45e8-f408-802436a0aa6b"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "\n",
        "# Download the file\n",
        "if not os.path.exists('./conll'):\n",
        "  print('Downloading dataset...')\n",
        "  !wget -P conll/ \"https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/train.txt\"\n",
        "  !wget -P conll/ \"https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/test.txt\"\n",
        "  !wget -P conll/ \"https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/valid.txt\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "--2021-06-05 18:57:28--  https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/train.txt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/train.txt [following]\n",
            "--2021-06-05 18:57:29--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3283418 (3.1M) [text/plain]\n",
            "Saving to: â€˜conll/train.txtâ€™\n",
            "\n",
            "train.txt           100%[===================>]   3.13M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-06-05 18:57:29 (67.0 MB/s) - â€˜conll/train.txtâ€™ saved [3283418/3283418]\n",
            "\n",
            "--2021-06-05 18:57:29--  https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/test.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/test.txt [following]\n",
            "--2021-06-05 18:57:29--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748093 (731K) [text/plain]\n",
            "Saving to: â€˜conll/test.txtâ€™\n",
            "\n",
            "test.txt            100%[===================>] 730.56K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-06-05 18:57:29 (60.7 MB/s) - â€˜conll/test.txtâ€™ saved [748093/748093]\n",
            "\n",
            "--2021-06-05 18:57:29--  https://github.com/davidsbatista/NER-datasets/raw/master/CONLL2003/valid.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/valid.txt [following]\n",
            "--2021-06-05 18:57:29--  https://raw.githubusercontent.com/davidsbatista/NER-datasets/master/CONLL2003/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827441 (808K) [text/plain]\n",
            "Saving to: â€˜conll/valid.txtâ€™\n",
            "\n",
            "valid.txt           100%[===================>] 808.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-06-05 18:57:30 (41.1 MB/s) - â€˜conll/valid.txtâ€™ saved [827441/827441]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgkEaOFk2eiv"
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for token classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, words, labels):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            words: list. The words of the sequence.\n",
        "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.words = words\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESI5E3-zrnBJ"
      },
      "source": [
        "def read_examples_from_file(data_dir, mode):\n",
        "    file_path = os.path.join(data_dir, \"{}.txt\".format(mode))\n",
        "    guid_index = 1\n",
        "    examples = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
        "                if words:\n",
        "                    examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index),\n",
        "                                                 words=words,\n",
        "                                                 labels=labels))\n",
        "                    guid_index += 1\n",
        "                    words = []\n",
        "                    labels = []\n",
        "            else:\n",
        "                splits = line.split(\" \")\n",
        "                words.append(splits[0])\n",
        "                if len(splits) > 1:\n",
        "                    labels.append(splits[-1].replace(\"\\n\", \"\"))\n",
        "                else:\n",
        "                    # Examples could have no label for mode = \"test\"\n",
        "                    labels.append(\"O\")\n",
        "        if words:\n",
        "            examples.append(InputExample(guid=\"%s-%d\".format(mode, guid_index),\n",
        "                                         words=words,\n",
        "                                         labels=labels))\n",
        "    return examples"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-2yiII8HuQ"
      },
      "source": [
        "def convert_examples_to_features(examples,\n",
        "                                 label_list,\n",
        "                                 max_seq_length,\n",
        "                                 tokenizer):\n",
        "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "    cls_token=\"[CLS]\"\n",
        "    cls_token_segment_id=1\n",
        "    sep_token=\"[SEP]\"\n",
        "    sep_token_extra=False\n",
        "    pad_on_left=False\n",
        "    pad_token=0\n",
        "    pad_token_segment_id=0\n",
        "    pad_token_label_id=-1\n",
        "    sequence_a_segment_id=0\n",
        "    mask_padding_with_zero=True\n",
        "    cls_token_at_end = False\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        # if ex_index % 10000 == 0:\n",
        "        #     logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
        "\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "        for word, label in zip(example.words, example.labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
        "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
        "        special_tokens_count = 3 if sep_token_extra else 2\n",
        "        if len(tokens) > max_seq_length - special_tokens_count:\n",
        "            tokens = tokens[:(max_seq_length - special_tokens_count)]\n",
        "            label_ids = label_ids[:(max_seq_length - special_tokens_count)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens += [sep_token]\n",
        "        label_ids += [pad_token_label_id]\n",
        "        if sep_token_extra:\n",
        "            # roberta uses an extra separator b/w pairs of sentences\n",
        "            tokens += [sep_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if cls_token_at_end:\n",
        "            tokens += [cls_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "            segment_ids += [cls_token_segment_id]\n",
        "        else:\n",
        "            tokens = [cls_token] + tokens\n",
        "            label_ids = [pad_token_label_id] + label_ids\n",
        "            segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
        "        else:\n",
        "            input_ids += ([pad_token] * padding_length)\n",
        "            input_mask += ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "            segment_ids += ([pad_token_segment_id] * padding_length)\n",
        "            label_ids += ([pad_token_label_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        assert len(label_ids) == max_seq_length\n",
        "\n",
        "        # if ex_index < 5:\n",
        "        #     logger.info(\"*** Example ***\")\n",
        "        #     logger.info(\"guid: %s\", example.guid)\n",
        "        #     logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
        "        #     logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
        "        #     logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
        "        #     logger.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
        "        #     logger.info(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=label_ids))\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_labels(path):\n",
        "    if path:\n",
        "        with open(path, \"r\") as f:\n",
        "            labels = f.read().splitlines()\n",
        "        if \"O\" not in labels:\n",
        "            labels = [\"O\"] + labels\n",
        "        return labels\n",
        "    else:\n",
        "        return [\"O\", \"B-MISC\", \"I-MISC\",  \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWXt05Kw11Bb",
        "outputId": "0833d435-a7b6-4eb2-aeb9-0aa7bd5d4e7e"
      },
      "source": [
        "training_examples = read_examples_from_file('./conll/', 'train')\n",
        "validation_examples = read_examples_from_file('./conll/', 'valid')\n",
        "testing_examples = read_examples_from_file('./conll/', 'test')\n",
        "\n",
        "print('\\n\\n---------- training examples -----------')\n",
        "for example in training_examples[:5]:\n",
        "  print(example.words, example.labels)\n",
        "\n",
        "print('\\n\\n---------- validation examples -----------')\n",
        "for example in validation_examples[:5]:\n",
        "  print(example.words, example.labels)\n",
        "\n",
        "\n",
        "print('\\n\\n---------- testing examples -----------')\n",
        "for example in testing_examples[:5]:\n",
        "  print(example.words, example.labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "---------- training examples -----------\n",
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'] ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "['Peter', 'Blackburn'] ['B-PER', 'I-PER']\n",
            "['BRUSSELS', '1996-08-22'] ['B-LOC', 'O']\n",
            "['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'] ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.'] ['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "---------- validation examples -----------\n",
            "['CRICKET', '-', 'LEICESTERSHIRE', 'TAKE', 'OVER', 'AT', 'TOP', 'AFTER', 'INNINGS', 'VICTORY', '.'] ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['LONDON', '1996-08-30'] ['B-LOC', 'O']\n",
            "['West', 'Indian', 'all-rounder', 'Phil', 'Simmons', 'took', 'four', 'for', '38', 'on', 'Friday', 'as', 'Leicestershire', 'beat', 'Somerset', 'by', 'an', 'innings', 'and', '39', 'runs', 'in', 'two', 'days', 'to', 'take', 'over', 'at', 'the', 'head', 'of', 'the', 'county', 'championship', '.'] ['B-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['Their', 'stay', 'on', 'top', ',', 'though', ',', 'may', 'be', 'short-lived', 'as', 'title', 'rivals', 'Essex', ',', 'Derbyshire', 'and', 'Surrey', 'all', 'closed', 'in', 'on', 'victory', 'while', 'Kent', 'made', 'up', 'for', 'lost', 'time', 'in', 'their', 'rain-affected', 'match', 'against', 'Nottinghamshire', '.'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
            "['After', 'bowling', 'Somerset', 'out', 'for', '83', 'on', 'the', 'opening', 'morning', 'at', 'Grace', 'Road', ',', 'Leicestershire', 'extended', 'their', 'first', 'innings', 'by', '94', 'runs', 'before', 'being', 'bowled', 'out', 'for', '296', 'with', 'England', 'discard', 'Andy', 'Caddick', 'taking', 'three', 'for', '83', '.'] ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "---------- testing examples -----------\n",
            "['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.'] ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "['Nadim', 'Ladki'] ['B-PER', 'I-PER']\n",
            "['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06'] ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.'] ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.'] ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AKt5CNbI7TP"
      },
      "source": [
        "# 3. Tokenization & Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFJKT5OJASr"
      },
      "source": [
        "# 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUcIlJB0JEmi"
      },
      "source": [
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "329ef6e56f8c4e0aa337c5396cab2392",
            "961c9b0d24f9498ebddc5502abe068f5",
            "b8ac9e2e7574414ab62766c8ffbb1fdb",
            "21cf81d6cd9f436a94ca1d441261792a",
            "1f14f4dfb281418dbf99ae0bd7bba25e",
            "34dba461826a4855a8a6f1a0ce5fb0e9",
            "3a4fb3b13c804fc980e92282435b4836",
            "990573dfd32040d6a078a0446c7d136a",
            "08ecc357c2ef4a2593f9c85f057a366d",
            "3a6a9f47689042208a5f1d6f2e96210d",
            "ddd9efd193d547178e8d1760a05700a3",
            "8325d41a705242f0b56dfc098e139529",
            "a270cee97dbf4abe9a9072e38324aec1",
            "bc532ce09cd942dd9aa35f0df51288ec",
            "6baf67675ad848cf9e8571eeb44cc60b",
            "a2992b632ec0424ab3951e8f50d6d865",
            "3f67ae1bd2cb4ac18c28ea970e99b843",
            "c9f1415aedef437b86f0d989f81f917b",
            "6089ee741f9b4e97af0f61a67832ec38",
            "4693d060ddbf4e6db60c44374cb8236f",
            "41bdcedaca7f4e738c6547d920c91506",
            "0c7d04d2f865474f933612a1d66eb758",
            "519101dd5eb34071abc46be234ba1cf6",
            "c7c6612af21e41b18ce282b59ee57a13"
          ]
        },
        "id": "IKodpdl4JLOp",
        "outputId": "16d77a88-c57a-4aa3-e375-68b6cdae29d7"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "329ef6e56f8c4e0aa337c5396cab2392",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08ecc357c2ef4a2593f9c85f057a366d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f67ae1bd2cb4ac18c28ea970e99b843",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlutRuxgKHgr",
        "outputId": "60a75c3a-a066-4907-d5ab-62c12220de7f"
      },
      "source": [
        "label_list = get_labels('')\n",
        "max_seq_length = 64\n",
        "label_list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vmvx4d4l7j"
      },
      "source": [
        "train_features = convert_examples_to_features(training_examples, label_list, max_seq_length,tokenizer)\n",
        "valid_features = convert_examples_to_features(validation_examples, label_list, max_seq_length,tokenizer)\n",
        "test_features = convert_examples_to_features(testing_examples, label_list, max_seq_length,tokenizer)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PxV_1SQTGx"
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "def convert_feature_to_tensor(features):\n",
        "  all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "  all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "  all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "  all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
        "\n",
        "  dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "  return dataset"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HNlarirj5q6"
      },
      "source": [
        "train_dataset = convert_feature_to_tensor(train_features)\n",
        "valid_dataset = convert_feature_to_tensor(valid_features)\n",
        "test_dataset = convert_feature_to_tensor(test_features)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXRZvF_5oD_V"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSSFSlyTkJOQ"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            valid_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(valid_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHqjuVVbok0S"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWl-mdJGop8h"
      },
      "source": [
        "# 4.1. BertForTokenClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90JKd-zvo1ye"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
        "\n",
        "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "Here is the current list of classes provided for fine-tuning:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* BertForSequenceClassification\n",
        "* **BertForTokenClassification** - The one we'll use.\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT579no0oN4g",
        "outputId": "57f80fe1-472f-4b2f-a4fa-bf299d66925b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d835b37cb0294de4bffa7c94200aac48",
            "325ff2bcd4924920bc709a0c72e6472e",
            "61c9cd2045d74133bcac7fab657b878c",
            "e54b8805bcc046dc940f0e582365b04b",
            "39f58ed60b6b438299e734c90e8a384b",
            "0611a887fffc4d898ea3fc74a5fb027c",
            "355184d1dfcf47f29cbd67f7c55bfe2c",
            "0d7d0605d7564a4bbedb0d153b6cc961",
            "5ceb2de58fcd42f1a2eb943f711c6bff",
            "f48cbbf5e64c4a3f97f56db2e8a7ca8c",
            "a0eabd9975b84593b6101a8724c84564",
            "221e29d7175442c59dfedcca6db58099",
            "75df1dbb46174741bd4ebe4d069f056e",
            "a17b091989964d52ad8c5c7b612b7c10",
            "109ab3f3225a457da38326a0baba85a4",
            "f96037074c994e36a99d15c768ced08e"
          ]
        }
      },
      "source": [
        "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(label_list), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d835b37cb0294de4bffa7c94200aac48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ceb2de58fcd42f1a2eb943f711c6bff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcVYhCccvBLQ",
        "outputId": "fbf7d8e3-69ae-4f45-8ecb-7efb45794b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 199 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.encoder.layer.11.output.LayerNorm.weight                 (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias                   (768,)\n",
            "classifier.weight                                           (9, 768)\n",
            "classifier.bias                                                 (9,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1YMi0ZmvXRF"
      },
      "source": [
        "# 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_DGc2LJvehs"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satlZFtNvQCl"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
        "                  weight_decay = 0.01 # Decoupled weight decay to apply\n",
        "                )\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsydjIVkvl54"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfrKaoluvtax"
      },
      "source": [
        "# 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY51tOnhv0N3"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
        "\n",
        "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n",
        "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
        "\n",
        "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7LX52wpvpfY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0tHAH7Bv6MK"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMAKLZW4v-FS"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNRH_hwwFUV",
        "outputId": "7112b83e-f542-408c-98d8-a16d286535e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    439.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    439.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    439.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    439.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    439.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    439.    Elapsed: 0:01:33.\n",
            "  Batch   280  of    439.    Elapsed: 0:01:48.\n",
            "  Batch   320  of    439.    Elapsed: 0:02:03.\n",
            "  Batch   360  of    439.    Elapsed: 0:02:19.\n",
            "  Batch   400  of    439.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    439.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    439.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    439.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    439.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    439.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    439.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    439.    Elapsed: 0:01:48.\n",
            "  Batch   320  of    439.    Elapsed: 0:02:03.\n",
            "  Batch   360  of    439.    Elapsed: 0:02:18.\n",
            "  Batch   400  of    439.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    439.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    439.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    439.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    439.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    439.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    439.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    439.    Elapsed: 0:01:48.\n",
            "  Batch   320  of    439.    Elapsed: 0:02:03.\n",
            "  Batch   360  of    439.    Elapsed: 0:02:19.\n",
            "  Batch   400  of    439.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    439.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    439.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    439.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    439.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    439.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    439.    Elapsed: 0:01:33.\n",
            "  Batch   280  of    439.    Elapsed: 0:01:48.\n",
            "  Batch   320  of    439.    Elapsed: 0:02:03.\n",
            "  Batch   360  of    439.    Elapsed: 0:02:19.\n",
            "  Batch   400  of    439.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:10 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOLCfTbvwM8z",
        "outputId": "04a7303b-7291-42a5-e6a6-4d9bc1da92ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.36e-04</td>\n",
              "      <td>1.06e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0:02:49</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.03e-04</td>\n",
              "      <td>1.06e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0:02:49</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.03e-04</td>\n",
              "      <td>1.06e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0:02:49</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.03e-04</td>\n",
              "      <td>1.06e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0:02:49</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           2.36e-04     1.06e-04            0.0       0:02:49         0:00:14\n",
              "2           2.03e-04     1.06e-04            0.0       0:02:49         0:00:14\n",
              "3           2.03e-04     1.06e-04            0.0       0:02:49         0:00:14\n",
              "4           2.03e-04     1.06e-04            0.0       0:02:49         0:00:14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAys14hpwib3",
        "outputId": "aeb690b1-3df6-42bc-ec8c-2f09c9a78ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mryqdGkxwq4o"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLDp4A77wlky",
        "outputId": "07077ad3-de09-436c-b9d2-eff4d252d88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7a6963394215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prediction on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicting labels for {:,} test sentences...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Put model in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwt6w5cVw3oj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}